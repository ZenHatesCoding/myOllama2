# MyOllama - 智能对话助手

基于 Flask 和 Ollama 的智能对话助手，支持文档问答、多模型选择、语音交互、截图识别等功能。

## 测试推送

### 核心功能
- **多文档格式支持**：PDF、Word (.docx)、纯文本 (.txt)
- **图片上传**：支持图片上传和多模态问答
  - 支持上传多张图片
  - 图片显示缩略图预览
  - 可单独删除每个图片
  - 自动切换到多模态模型（qwen3-vl:8b）
- **截图识别**：支持屏幕截图和区域选择
  - 点击"📸 截图"按钮启动截图
  - 全屏显示，鼠标拖拽选择区域
  - 按 ESC 键可取消截图
  - 截图自动上传到对话中
- **智能问答**：基于 LangChain 和 Ollama 的文档问答系统
- **流式输出**：实时显示生成内容，提供流畅的用户体验
- **中断操作**：可随时停止正在生成的回答

### 对话管理
- **多对话支持**：创建和管理多个独立对话
- **对话列表**：左侧边栏显示所有对话，支持快速切换
- **对话分叉**：基于现有对话创建新的分支对话
- **智能命名**：
  - 首次对话：使用用户问题前20个字符
  - 后续对话：AI 生成摘要，使用摘要前30个字符
  - 自动更新对话标题
- **对话删除**：可删除不需要的对话

### 语音功能
- **语音识别**：支持中英文语音输入，自动转换为文字
  - 基于浏览器原生 Web Speech API
  - 支持离线模式（需下载语言包）
  - 可配置录音时长（5-120秒，默认30秒）
- **语音朗读**：支持中英文语音播放
  - 基于浏览器原生 SpeechSynthesis API
  - 完全离线支持
  - 可随时开关，自动停止正在播放的语音

### 模型选择
- **多模型支持**：
  - qwen3:8b（默认）
  - qwen3:14b
  - deepseek-r1:8b
  - qwen3-vl:8b（多模态模型，支持图片问答）
- **灵活切换**：在主界面直接选择模型，每次提问使用当前选中的模型
- **自动切换**：上传图片或截图时自动切换到多模态模型（qwen3-vl:8b）
- **固定摘要模型**：摘要生成始终使用 qwen3:8b，确保稳定性

### 配置选项
- **上下文轮数**：控制对话历史保留的轮数（默认5轮）
- **语音识别语言**：支持中文（zh-CN）和英文（en-US）
- **语音合成语言**：支持中文（zh-CN）和英文（en-US）
- **录音时长限制**：可配置语音输入的最长时长（5-120秒）

### 界面优化
- **响应式布局**：按钮自动换行，窗口缩放时不会遮挡输入框
- **实时 Markdown 渲染**：流式输出时实时显示格式化内容
- **优化的输入区域**：输入框和功能按钮分层显示，交互更清晰

## 环境要求

- Python 3.8+
- Ollama 服务（运行在 http://localhost:11434）
- 推荐使用的 Ollama 模型：
  - 嵌入模型：`nomic-embed-text`
  - LLM 模型：`qwen3:8b`、`qwen3:14b`、`deepseek-r1:8b`
  - 多模态模型：`qwen3-vl:8b`（支持图片问答）
- 浏览器要求：
  - **推荐使用 Microsoft Edge 浏览器**（完全支持语音功能，无需翻墙）
  - 或使用 Chrome 浏览器
  - 需要麦克风权限（语音识别功能）

## 安装步骤

1. 在父文件夹的 venv 环境中安装依赖：
```bash
cd ..
.venv\Scripts\activate
pip install -r myOllama\requirements.txt
```

2. 确保已安装并启动 Ollama 服务：
```bash
# 下载并运行 Ollama
# 访问 https://ollama.ai 下载安装

# 拉取所需的模型
ollama pull nomic-embed-text
ollama pull qwen3:8b
ollama pull qwen3:14b
ollama pull deepseek-r1:8b
ollama pull qwen3-vl:8b
```

## 使用方法

### 启动应用

**Windows:**
```bash
myOllama\run_flask.bat
```

**手动启动:**
```bash
python myOllama\app.py
```

应用将在 http://localhost:5000 启动

### 基本使用流程

1. 打开浏览器访问 **http://localhost:5000**（推荐使用 Edge 浏览器）
   - **重要**：必须使用 `http://localhost:5000` 访问，不能使用 IP 地址（如 `http://192.168.x.x:5000`）
   - Edge 浏览器对 HTTP 的 IP 地址默认阻止麦克风权限，只有 localhost 才允许

2. **上传文档**（可选）：
   - 点击"📤 上传文档"按钮上传文档（支持 PDF、Word、TXT）
   - 等待文档解析完成
   - 文档信息会显示在文档栏中

3. **上传图片**（可选）：
   - 点击"🖼️ 上传图片"按钮上传图片
   - 支持上传多张图片
   - 图片会显示缩略图预览
   - 可点击每个图片上的"✕"按钮单独删除
   - 上传图片后自动切换到多模态模型（qwen3-vl:8b）
   - 删除所有图片后可切换回其他模型

4. **截图识别**（可选）：
   - 点击"📸 截图"按钮启动截图
   - 屏幕会显示全屏窗口（半透明）
   - 用鼠标拖拽框选需要截图的区域
   - 松开鼠标完成截图
   - 截图自动上传到对话中
   - 按 **ESC** 键可取消截图

5. **选择模型**：
   - 在模型选择下拉框中选择你想要的模型
   - 可选模型：qwen3:8b、qwen3:14b、deepseek-r1:8b、qwen3-vl:8b
   - 上传图片或截图时自动切换到多模态模型
   - 可以随时切换模型（有图片时只能使用多模态模型）

6. **输入问题**（三种方式）：
   - **文字输入**：在文本框中直接输入问题
   - **语音输入**：点击"🎤 开始语音输入"按钮，说话后自动转换为文字
   - **快捷键**：按 Ctrl+Enter 直接提交

7. **查看回答**：
   - 回答会实时流式显示
   - 支持完整的 Markdown 格式渲染
   - 可随时点击"⏹ 停止生成"中断操作

8. **语音朗读**：
   - 点击"🔇 语音朗读"按钮开启语音朗读
   - 开启后，新生成的回答会自动朗读
   - 再次点击可停止朗读

### 对话管理

- **新建对话**：点击左侧边栏的"➕ 新建对话"按钮
- **切换对话**：点击对话列表中的任意对话进行切换
- **分叉对话**：在对话列表中点击"🔄"按钮，基于当前对话创建新的分支
- **删除对话**：在对话列表中点击"🗑️"按钮删除对话

### 配置设置

点击"⚙️ 配置"按钮打开配置对话框：

- **上下文轮数**：设置对话历史保留的轮数（默认5轮）
- **语音识别语言**：选择语音识别的语言（中文/英文）
- **语音合成语言**：选择语音合成的语言（中文/英文）
- **语音输入最长时长**：设置录音的最长时长（5-120秒，默认30秒）

### 语音识别功能说明

- **支持语言**：中文（zh-CN）和英文（en-US）
- **录音限制**：可在配置中设置最长时长（5-120秒），超时自动停止
- **使用方式**：
  1. 点击"🎤 开始语音输入"按钮
  2. 允许浏览器访问麦克风
  3. 说出您的问题
  4. 系统自动将语音转换为文字填入输入框
  5. 确认后点击"发送"提交
- **离线模式**：Edge 浏览器支持离线语音识别，可在设置中下载语言包
  - 访问 `edge://settings/languages`
  - 添加语言并勾选"允许此语言使用离线语音识别"

### 语音朗读功能说明

- **支持语言**：中文（zh-CN）和英文（en-US）
- **使用方式**：
  1. 点击"🔇 语音朗读"按钮开启语音朗读
  2. 开启后，新生成的回答会自动朗读
  3. 关闭时，立即停止当前正在播放的语音
  4. 重新开启时，重新朗读当前显示的回答
- **离线模式**：Edge 浏览器支持离线语音合成，无需额外设置
- **语音选择**：系统自动根据回答内容选择中文或英文语音

### 截图功能说明

- **使用方式**：
  1. 点击"📸 截图"按钮
  2. 屏幕会显示全屏窗口（半透明）
  3. 用鼠标拖拽框选需要截图的区域
  4. 松开鼠标完成截图
  5. 截图自动上传到对话中
  6. 按 **ESC** 键可取消截图
- **注意事项**：
  - 截图区域最小为 10x10 像素
  - 支持多显示器环境
  - 截图会自动压缩优化

### 智能对话命名

- **首次对话**：使用用户第一个问题的前20个字符作为标题
- **后续对话**：AI 自动生成对话摘要，使用摘要前30个字符作为标题
- **自动更新**：每次回答完成后自动更新对话标题
- **摘要模型**：始终使用 qwen3:8b 模型生成摘要，确保稳定性

## 项目结构

```
myOllama/
├── app.py                 # Flask 应用主文件
├── requirements.txt       # Python 依赖
├── run_flask.bat         # Windows 启动脚本
├── readme.md             # 项目说明文档
├── screenshot.py         # 截图功能模块
├── models.py             # 数据模型
├── routes.py            # API 路由
├── utils.py             # 工具函数
├── static/
│   ├── css/
│   │   └── style.css     # 样式文件
│   └── js/
│       └── app.js        # 前端 JavaScript
└── templates/
    └── index.html        # 前端页面
```

## 技术栈

- **后端**: Flask
- **AI/ML**: LangChain, Ollama
- **向量存储**: FAISS
- **文档处理**: PyPDFLoader, python-docx
- **截图功能**: mss, tkinter, PIL
- **前端**: 原生 HTML/CSS/JavaScript
- **Markdown 渲染**: marked.js
- **语音识别**: Web Speech API - SpeechRecognition（浏览器原生，无需额外依赖）
- **语音合成**: Web Speech API - SpeechSynthesis（浏览器原生，无需额外依赖）

## 注意事项

### 通用注意事项
- 确保 Ollama 服务正在运行（http://localhost:11434）
- 首次使用需要下载 Ollama 模型
- 大文件处理可能需要较长时间
- 建议使用 Chrome 或 Edge 浏览器以获得最佳体验

### 语音识别功能
- 首次使用需要允许浏览器访问麦克风
- 推荐使用 Edge 浏览器（无需翻墙，支持离线模式）
- **必须使用 `http://localhost:5000` 访问，不能使用 IP 地址**
- Edge 浏览器对 HTTP 的 IP 地址默认阻止麦克风权限，只有 localhost 才允许
- 如需完全离线使用，请在浏览器设置中下载语言包
- 录音时长可在配置中设置（5-120秒），超时自动停止
- 语音识别依赖浏览器功能，不同浏览器识别准确率可能略有差异

### 语音朗读功能
- 首次使用无需额外设置，浏览器直接支持
- 推荐使用 Edge 浏览器（语音质量好，完全支持离线）
- 开启后，新生成的回答会自动朗读
- 可随时点击开关停止或重新播放语音
- 系统自动根据回答内容选择中文或英文语音
- 语音合成依赖浏览器功能，不同浏览器语音质量可能略有差异

### 截图功能
- 截图功能需要 Python tkinter 支持（Python 默认包含）
- 截图时会短暂显示全屏窗口
- 按 ESC 键可随时取消截图
- 截图区域最小为 10x10 像素
- 支持多显示器环境

### 模型使用
- 摘要生成（自动对话命名、上下文摘要）始终使用固定的 `qwen3:8b` 模型
- 问答功能可以使用用户选择的任意模型
- 确保已下载所需的 Ollama 模型

## 常见问题

**Q: 为什么语音识别不工作？**
A: 请确保：
1. 使用 `http://localhost:5000` 访问，而不是 IP 地址
2. 已允许浏览器访问麦克风
3. 使用 Edge 或 Chrome 浏览器
4. 检查浏览器设置中是否启用了麦克风权限

**Q: 如何完全离线使用语音功能？**
A: 在 Edge 浏览器中：
1. 访问 `edge://settings/languages`
2. 添加需要的语言（如中文、英文）
3. 勾选"允许此语言使用离线语音识别"

**Q: 为什么模型选择不生效？**
A: 请确保：
1. 已在 Ollama 中下载了对应的模型
2. Ollama 服务正在运行
3. 模型名称正确（区分大小写）
4. 如果上传了图片或截图，只能使用多模态模型（qwen3-vl:8b）

**Q: 如何使用图片问答功能？**
A:
1. 点击"🖼️ 上传图片"按钮上传图片
2. 支持上传多张图片，图片会显示缩略图
3. 可点击每个图片上的"✕"按钮单独删除
4. 上传图片后自动切换到多模态模型（qwen3-vl:8b）
5. 输入问题，模型会基于图片内容回答
6. 删除所有图片后可切换回其他模型

**Q: 如何使用截图功能？**
A:
1. 点击"📸 截图"按钮启动截图
2. 屏幕会显示全屏窗口（半透明）
3. 用鼠标拖拽框选需要截图的区域
4. 松开鼠标完成截图
5. 截图自动上传到对话中
6. 按 **ESC** 键可取消截图

**Q: 为什么图片问答不工作？**
A: 请确保：
1. 已下载多模态模型：`ollama pull qwen3-vl:8b`
2. Ollama 服务正在运行
3. 图片格式正确（支持常见图片格式）
4. 图片大小适中（系统会自动压缩到 512x512）

**Q: 对话标题是如何生成的？**
A:
- 首次对话：使用用户第一个问题的前20个字符
- 后续对话：AI 自动生成对话摘要，使用摘要前30个字符
- 每次回答完成后自动更新对话标题
- 摘要生成使用 qwen3:8b 模型

**Q: 为什么 Markdown 显示不正常？**
A: 已修复此问题。现在流式输出时会实时渲染 Markdown 格式，无需切换对话。

**Q: 为什么按钮和输入框重叠？**
A: 已修复此问题。现在输入框和功能按钮分层显示，窗口缩放时按钮会自动换行，不会遮挡输入框。

**Q: 如何提高问答质量？**
A:
1. 上传相关文档，系统会基于文档内容回答
2. 调整上下文轮数配置，保留更多历史对话
3. 尝试不同的模型，选择最适合的模型
4. 提供清晰、具体的问题
5. 使用截图功能提供视觉信息

## 更新日志

### v4.0.0
- 添加截图识别功能
  - 支持全屏截图和区域选择
  - 按 ESC 键可取消截图
  - 截图自动上传到对话
- 优化对话命名功能
  - 首次对话使用用户问题前20个字符
  - 后续对话使用 AI 生成的摘要（前30个字符）
  - 自动更新对话标题
- 修复 Markdown 显示问题
  - 流式输出时实时渲染 Markdown
  - 无需切换对话即可看到正确格式
- 优化界面布局
  - 输入框和功能按钮分层显示
  - 窗口缩放时按钮自动换行
  - 解决按钮遮挡输入框的问题
- 修复 ESC 无法取消截图的问题

### v3.0.0
- 添加图片上传和多模态问答功能
- 支持上传多张图片
- 图片显示缩略图预览
- 可单独删除每个图片
- 自动切换到多模态模型（qwen3-vl:8b）
- 修复停止按钮失效问题
- 修复图片预览显示问题
- 统一上传图片和文档按钮风格

### v2.0.0
- 添加多对话管理功能
- 添加对话分叉功能
- 添加自动对话命名
- 添加模型选择功能
- 添加配置对话框
- 改进语音功能（可配置录音时长）
- 优化界面交互，解决刷新闪烁问题
- 改进 Markdown 渲染

### v1.0.0
- 初始版本
- 支持文档上传和问答
- 支持语音识别和朗读
- 支持流式输出

## 许可证

MIT License
